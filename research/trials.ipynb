{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a975bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bd50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\LLM\\\\Medical_ChatBot_Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd36f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f157576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\LLM\\\\Medical_ChatBot_Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33ecb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable symlink warning from Hugging Face Hub (useful in environments like Windows where symlinks can cause issues)\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe960cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader # PDF loader to read and extract text from PDF documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Text splitter to break documents into smaller chunks for processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a585f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Function to extract data from all PDF files in a directory\n",
    "def load_pdf_file(data):\n",
    "    # Initialize a DirectoryLoader to load all PDF files matching the pattern in the specified folder\n",
    "    loader = DirectoryLoader(\n",
    "        data,                       # Path to the directory containing PDF files\n",
    "        glob=\"*.pdf\",               # Only match files with .pdf extension\n",
    "        loader_cls=PyPDFLoader      # Use PyPDFLoader to parse and extract text from the PDF files\n",
    "    )\n",
    "\n",
    "    # Load all the documents from the directory\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Return the list of loaded documents (each representing content from one PDF)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b3fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 637\n",
      "\n",
      "Preview of the first document:\n",
      "\n",
      "page_content='' metadata={'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "First 500 characters of the 111th document:\n",
      "‚Ä¢ having large blocks of time taken up by alcohol use\n",
      "‚Ä¢ choosing to drink at the expense of other important\n",
      "tasks or activities\n",
      "‚Ä¢ drinking despite evidence of negative effects on one‚Äôs\n",
      "health, relationships, education, or job\n",
      "Alcohol abuse requires that one of the following four\n",
      "criteria is met. Because of drinking, a person repeatedly:\n",
      "‚Ä¢ fails to live up to his or her most important responsibili-\n",
      "ties\n",
      "‚Ä¢ physically endangers him or herself, or others (for\n",
      "example, by drinking when driving)\n",
      "‚Ä¢ get\n",
      "\n",
      "Metadata of the first document:\n",
      "{'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Load and extract data from all PDF files located in the \"Data/\" directory\n",
    "extracted_data = load_pdf_file(data=\"Data/\")\n",
    "\n",
    "# View number of documents loaded\n",
    "print(f\"Number of documents loaded: {len(extracted_data)}\")\n",
    "\n",
    "# Preview of the first document\n",
    "print(\"\\nPreview of the first document:\\n\")\n",
    "print(extracted_data[0])\n",
    "\n",
    "# Safely print the 110th page (if it exists)\n",
    "if len(extracted_data) > 110:\n",
    "    print(f\"\\nFirst 500 characters of the 111th document:\\n{extracted_data[110].page_content[:500]}\")\n",
    "else:\n",
    "    print(f\"\\nThere are only {len(extracted_data)} documents. Cannot access the 111th document.\")\n",
    "\n",
    "# Metadata of the first document\n",
    "print(\"\\nMetadata of the first document:\")\n",
    "print(extracted_data[0].metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74371135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the extracted PDF documents into smaller text chunks\n",
    "def text_split(data=extracted_data, chunk_size=500, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Splits input documents into smaller chunks for processing by LLMs.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of documents loaded from PDFs.\n",
    "        chunk_size (int): Maximum number of characters in a chunk.\n",
    "        chunk_overlap (int): Number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "        List of split text chunks.\n",
    "    \"\"\"\n",
    "    # Initialize the text splitter with specified chunk size and overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Split the documents into text chunks\n",
    "    text_chunks = text_splitter.split_documents(data)\n",
    "    \n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2108894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks is : 5859\n"
     ]
    }
   ],
   "source": [
    "# Split the extracted documents into smaller chunks\n",
    "text_chunks = text_split(extracted_data)\n",
    "\n",
    "# Print the total number of chunks created\n",
    "print(f\"Length of Text Chunks is : {len(text_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287c69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the embedding model from Hugging Face\n",
    "def download_huggingface_embeddings():\n",
    "    # You can customize model_name or add model_kwargs like device='cuda' for GPU usage\n",
    "    embed_model = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return embed_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b45fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gawal\\anaconda3\\envs\\medibot_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding vector: 384\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding model\n",
    "embed_model = download_huggingface_embeddings()\n",
    "\n",
    "# Generate the embedding for the first text chunk\n",
    "embedding_vector = embed_model.embed_query(text_chunks[0].page_content)\n",
    "\n",
    "# Print the length of the embedding vector\n",
    "print(f\"Length of embedding vector: {len(embedding_vector)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717b105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a97fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC  # Import Pinecone client for gRPC API\n",
    "from pinecone import ServerlessSpec     # Import serverless deployment spec for Pinecone\n",
    "import os                               # Import os to access environment variables\n",
    "\n",
    "# Retrieve Pinecone API key from environment variable\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize the Pinecone client with the API key\n",
    "pc = PineconeGRPC(api_key=api_key)\n",
    "\n",
    "# Define the index name (must be lowercase and can include hyphens)\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Check if the index already exists to avoid duplication\n",
    "if not pc.has_index(index_name):\n",
    "    # Create a new Pinecone index with specified parameters\n",
    "    pc.create_index( \n",
    "        name=index_name,\n",
    "        dimension=384,              # Dimensionality of vectors (e.g., from MiniLM or similar)\n",
    "        metric=\"cosine\",            # Similarity metric to use (cosine distance)\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",            # Cloud provider\n",
    "            region=\"us-east-1\"      # Region where the index is hosted\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759f42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed each chunk and upsert the embeddings into your Pinecone Index.\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8202ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load existing index\n",
    "# Embed each chunk and upsert the embeddings into Pinecone Index\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8f8df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1baac0c3940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff12682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3b145818-8d34-4fb6-a80f-2d73b7210b13', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 609.0, 'page_label': '610', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2596\\nBronchiectasis\\nGEM -0433 to 0624 - B  10/22/03 6:09 PM  Page 596'),\n",
       " Document(id='d1338333-3e60-41c7-bd77-f98a4e80c4b4', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 610.0, 'page_label': '611', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='(Feb. 1995): 149+.\\nNicotra, M. Brooke, et al. ‚ÄúClinical, Pathophysiologic, and\\nMicrobiologic Characterization of Bronchiectasis in an\\nAging Cohort.‚Äù Chest 108 (Oct. 1995): 955+.\\nWeinberger, Steven E., and Ann Giudici Fettner. ‚ÄúDisease in\\nDisguise: Bronchiectasis.‚Äù Harvard Health Letter 21 (Feb.\\n1996): 6+.\\nORGANIZATIONS\\nAmerican Lung Association. 1740 Broadway, New York, NY\\n10019. (800) 586-4872. <http://www.lungusa.org>.\\nRosalyn Carson-DeWitt, MD\\nBronchiolitis see Respiratory syncytial virus'),\n",
       " Document(id='62aa06f9-ca60-4546-9756-b9bc612895c4', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 609.0, 'page_label': '610', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='bronchiectasis.\\nSymptoms of bronchiectasis include constant cough\\nand the production of infected sputum (sputum is a mix-\\nture of mucus and pus), which may be bloody. In some\\ncases, there may be wheezing and shortness of breath .\\nThe constant, low-level of infection may flare, resulting\\nin increased production of sputum, worsening of the\\ncough, and fever. The area of the lung served by the\\naffected bronchial tube may become severely infected,\\nresulting in pneumonia.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "retrieved_docs = retriever.invoke(\"What is Bronchiectasis\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c5b2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-tiny\",          # or mistral-small, mistral-medium, etc.\n",
    "    temperature=0.4,\n",
    "    max_tokens=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ff7d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "'''\n",
    "system_prompt = (\n",
    "    \"You are a highly accurate and rule-following medical assistant.\\n\"\n",
    "    \"You will ONLY answer questions using the provided context.\\n\"\n",
    "    \"If the answer is NOT found in the context, reply with exactly:\\n\"\n",
    "    \"\\\"I'm sorry, the information is not available.\\\"\\n\"\n",
    "    \"Do not paraphrase, do not reword, do not explain further.\\n\"\n",
    "    \"Do not use prior knowledge.\\n\"\n",
    "    \"Answer strictly based on the context, using no more than 3 medically accurate sentences.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")\n",
    "'''\n",
    "system_prompt = (\n",
    "    \"You are a highly accurate and rule-following medical assistant.\\n\"\n",
    "    \"If the answer isn't in the context, reply with exactly:\\n\"\n",
    "    \"I am not aware!.\\n\"\n",
    "    \"and Do not paraphrase Do not print a single word further.\\n\"\n",
    "    \"Stick to Context.\\n\"\n",
    "    \"Answer strictly based on the context, using no more than 3 medically accurate sentences.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=question_answer_chain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36326fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antiseptics are substances that inhibit the growth and development of microorganisms. They are used for wound surfaces after injury, skin preparation prior to injections or surgical procedures, oral hygiene, and disinfection of inanimate objects. Examples of commonly used antiseptics include benzalkonium chloride, chlorhexidine, iodine compounds, and alcohol.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are Antiseptics\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aea64535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am not aware!.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is BreakDance ?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am not aware! (This question is not related to the context provided.)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf5f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
